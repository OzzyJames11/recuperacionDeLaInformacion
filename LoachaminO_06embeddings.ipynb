{"metadata":{"kernelspec":{"display_name":"Python 3","language":"python","name":"python3"},"language_info":{"name":"python","version":"3.11.13","mimetype":"text/x-python","codemirror_mode":{"name":"ipython","version":3},"pygments_lexer":"ipython3","nbconvert_exporter":"python","file_extension":".py"},"kaggle":{"accelerator":"none","dataSources":[],"dockerImageVersionId":31192,"isInternetEnabled":true,"language":"python","sourceType":"notebook","isGpuEnabled":false}},"nbformat_minor":5,"nbformat":4,"cells":[{"id":"d3f8b5c16e7eb563","cell_type":"markdown","source":"# Ejercicio 6: Dense Retrieval e Introducción a FAISS\n\n## Objetivo de la práctica\n\nGenerar embeddings con sentence-transformers (SBERT, E5), e indexar documentos con FAISS ","metadata":{}},{"id":"802c73af-f1e8-4978-8c85-6d244650b1c1","cell_type":"code","source":"# importacion de librerias\nimport numpy as np\nimport pandas as pd","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-11-26T23:21:13.575285Z","iopub.execute_input":"2025-11-26T23:21:13.575571Z","iopub.status.idle":"2025-11-26T23:21:15.710364Z","shell.execute_reply.started":"2025-11-26T23:21:13.575547Z","shell.execute_reply":"2025-11-26T23:21:15.709393Z"}},"outputs":[],"execution_count":1},{"id":"922735e0-4b2e-452e-ac52-97bdc0c9f59a","cell_type":"code","source":"# --- LIMPIEZA ---\n#!pip uninstall -y protobuf\n\n# --- INSTALAR VERSION COMPATIBLE (evita el error GetPrototype) ---\n#!pip install protobuf==4.21.12\n\n# --- INSTALAR sentence-transformers, si no está ---\n#!pip install sentence-transformers\n\n# --- ACTUALIZAR transformers (si está desactualizado en Kaggle) ---\n#!pip install --upgrade transformers\n","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-11-26T23:21:15.712109Z","iopub.execute_input":"2025-11-26T23:21:15.712775Z","iopub.status.idle":"2025-11-26T23:21:15.717660Z","shell.execute_reply.started":"2025-11-26T23:21:15.712745Z","shell.execute_reply":"2025-11-26T23:21:15.716690Z"}},"outputs":[],"execution_count":2},{"id":"cdd69ed7fcbeef9d","cell_type":"markdown","source":"## Parte 0: Carga del Corpus\n### Actividad\n\n1. Carga el corpus 20 Newsgroups desde sklearn.datasets.fetch_20newsgroups.\n2. Limita el corpus a los primeros 2000 documentos para facilitar el procesamiento.","metadata":{}},{"id":"b00fbde6cfc88b","cell_type":"code","source":"from sklearn.datasets import fetch_20newsgroups\n\nnewsgroups = fetch_20newsgroups(subset='all', remove=('headers', 'footers', 'quotes'))\ndocs = newsgroups.data[:2000]\n\nprint(len(docs))","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-11-26T23:24:03.991942Z","iopub.execute_input":"2025-11-26T23:24:03.992291Z","iopub.status.idle":"2025-11-26T23:24:05.953682Z","shell.execute_reply.started":"2025-11-26T23:24:03.992263Z","shell.execute_reply":"2025-11-26T23:24:05.952782Z"}},"outputs":[{"name":"stdout","text":"2000\n","output_type":"stream"}],"execution_count":4},{"id":"b9184f4b3e66e20a","cell_type":"markdown","source":"## Parte 2: Generación de Embeddings\n### Actividad\n\n1. Usa dos modelos de sentence-transformers. Puedes usar: `'all-MiniLM-L6-v2'` (SBERT), o `'intfloat/e5-base'` (E5). Cuando uses E5, antepon `\"passage: \"` a cada documento antes de codificar.\n2. Genera los vectores de embeddings para todos los documentos usando el modelo seleccionado.\n3. Guarda los embeddings en un array de NumPy para su posterior indexación.","metadata":{}},{"id":"525ae7515c6169d9","cell_type":"code","source":"from sentence_transformers import SentenceTransformer\nimport numpy as np\n\n# Elegir modelos\nmodel_sbert = SentenceTransformer('all-MiniLM-L6-v2')\nmodel_e5 = SentenceTransformer('intfloat/e5-base')\n","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-11-26T23:24:19.054077Z","iopub.execute_input":"2025-11-26T23:24:19.055051Z","iopub.status.idle":"2025-11-26T23:25:19.003340Z","shell.execute_reply.started":"2025-11-26T23:24:19.055014Z","shell.execute_reply":"2025-11-26T23:25:19.001981Z"}},"outputs":[{"name":"stderr","text":"2025-11-26 23:24:36.510671: E external/local_xla/xla/stream_executor/cuda/cuda_fft.cc:477] Unable to register cuFFT factory: Attempting to register factory for plugin cuFFT when one has already been registered\nWARNING: All log messages before absl::InitializeLog() is called are written to STDERR\nE0000 00:00:1764199476.768088      47 cuda_dnn.cc:8310] Unable to register cuDNN factory: Attempting to register factory for plugin cuDNN when one has already been registered\nE0000 00:00:1764199476.839717      47 cuda_blas.cc:1418] Unable to register cuBLAS factory: Attempting to register factory for plugin cuBLAS when one has already been registered\n","output_type":"stream"},{"traceback":["\u001b[0;31m---------------------------------------------------------------------------\u001b[0m","\u001b[0;31mAttributeError\u001b[0m                            Traceback (most recent call last)","\u001b[0;31mAttributeError\u001b[0m: 'MessageFactory' object has no attribute 'GetPrototype'"],"ename":"AttributeError","evalue":"'MessageFactory' object has no attribute 'GetPrototype'","output_type":"error"},{"traceback":["\u001b[0;31m---------------------------------------------------------------------------\u001b[0m","\u001b[0;31mAttributeError\u001b[0m                            Traceback (most recent call last)","\u001b[0;31mAttributeError\u001b[0m: 'MessageFactory' object has no attribute 'GetPrototype'"],"ename":"AttributeError","evalue":"'MessageFactory' object has no attribute 'GetPrototype'","output_type":"error"},{"traceback":["\u001b[0;31m---------------------------------------------------------------------------\u001b[0m","\u001b[0;31mAttributeError\u001b[0m                            Traceback (most recent call last)","\u001b[0;31mAttributeError\u001b[0m: 'MessageFactory' object has no attribute 'GetPrototype'"],"ename":"AttributeError","evalue":"'MessageFactory' object has no attribute 'GetPrototype'","output_type":"error"},{"traceback":["\u001b[0;31m---------------------------------------------------------------------------\u001b[0m","\u001b[0;31mAttributeError\u001b[0m                            Traceback (most recent call last)","\u001b[0;31mAttributeError\u001b[0m: 'MessageFactory' object has no attribute 'GetPrototype'"],"ename":"AttributeError","evalue":"'MessageFactory' object has no attribute 'GetPrototype'","output_type":"error"},{"traceback":["\u001b[0;31m---------------------------------------------------------------------------\u001b[0m","\u001b[0;31mAttributeError\u001b[0m                            Traceback (most recent call last)","\u001b[0;31mAttributeError\u001b[0m: 'MessageFactory' object has no attribute 'GetPrototype'"],"ename":"AttributeError","evalue":"'MessageFactory' object has no attribute 'GetPrototype'","output_type":"error"},{"output_type":"display_data","data":{"text/plain":"modules.json:   0%|          | 0.00/349 [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"7cb4c78a75a642e0a32a58de06175d26"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"config_sentence_transformers.json:   0%|          | 0.00/116 [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"2570066d0e3e429fbe6e7ae0c27f857a"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"README.md: 0.00B [00:00, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"589b25fd1f3b48349fae247e7a267363"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"sentence_bert_config.json:   0%|          | 0.00/53.0 [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"534e98a49a4347048a5851fe68edfda8"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"config.json:   0%|          | 0.00/612 [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"24699f00c36e401f8b89cc9807349cb0"}},"metadata":{}},{"name":"stderr","text":"/usr/local/lib/python3.11/dist-packages/pydantic/_internal/_generate_schema.py:2249: UnsupportedFieldAttributeWarning: The 'repr' attribute with value False was provided to the `Field()` function, which has no effect in the context it was used. 'repr' is field-specific metadata, and can only be attached to a model field using `Annotated` metadata or by assignment. This may have happened because an `Annotated` type alias using the `type` statement was used, or if the `Field()` function was attached to a single member of a union type.\n  warnings.warn(\n/usr/local/lib/python3.11/dist-packages/pydantic/_internal/_generate_schema.py:2249: UnsupportedFieldAttributeWarning: The 'frozen' attribute with value True was provided to the `Field()` function, which has no effect in the context it was used. 'frozen' is field-specific metadata, and can only be attached to a model field using `Annotated` metadata or by assignment. This may have happened because an `Annotated` type alias using the `type` statement was used, or if the `Field()` function was attached to a single member of a union type.\n  warnings.warn(\n","output_type":"stream"},{"output_type":"display_data","data":{"text/plain":"model.safetensors:   0%|          | 0.00/90.9M [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"e5a98a6a445c4cc1819870d94cf403fc"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"tokenizer_config.json:   0%|          | 0.00/350 [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"7f12c49fb3444c5db39d990e0e610a49"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"vocab.txt: 0.00B [00:00, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"f3e9cf9e96034b24a40ff98dddc6285e"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"tokenizer.json: 0.00B [00:00, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"4f3fc7f1a29e4f12ab3b09f73fd6e551"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"special_tokens_map.json:   0%|          | 0.00/112 [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"17f332e4c0f0438eae42e40d9df3f618"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"config.json:   0%|          | 0.00/190 [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"878d5f7cbd654fd98ba8b44b4f7685fd"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"modules.json:   0%|          | 0.00/387 [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"7e635d64d3874421abda1bed1e9d18cb"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"README.md: 0.00B [00:00, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"2aacfacfe3494dc385ec890bbd09cde4"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"sentence_bert_config.json:   0%|          | 0.00/57.0 [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"7699da1572904e71a3d13a2682727b35"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"config.json:   0%|          | 0.00/645 [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"699b7c8f75cd44f28ff5eee5081509bd"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"model.safetensors:   0%|          | 0.00/438M [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"a59b0acc542b4c7c99ede2e7644265fc"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"tokenizer_config.json:   0%|          | 0.00/356 [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"0b7d91c14aa94605af00b8a6dab87dd8"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"vocab.txt: 0.00B [00:00, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"35845f0827dc4f94b1afcd71f54c8f03"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"tokenizer.json: 0.00B [00:00, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"8aa9d539792649919375b866da8d58a7"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"special_tokens_map.json:   0%|          | 0.00/112 [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"f04e6617ab67458a822370c9af2236b4"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"config.json:   0%|          | 0.00/200 [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"4377b02ed79e40759738ecdbb91c3e26"}},"metadata":{}}],"execution_count":5},{"id":"525019af-f5a1-49ae-98fe-721582f7356a","cell_type":"code","source":"# cargar modelos y generar embeddings\nfrom sentence_transformers import SentenceTransformer\n\n# Modelo SBERT\nmodel_sbert = SentenceTransformer('all-MiniLM-L6-v2', device='cpu')\n\n# Modelo E5\nmodel_e5 = SentenceTransformer('intfloat/e5-base', device='cpu')\n\nprint(\"Modelos cargados.\")\n","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-11-26T23:26:24.864660Z","iopub.execute_input":"2025-11-26T23:26:24.865868Z","iopub.status.idle":"2025-11-26T23:26:26.358862Z","shell.execute_reply.started":"2025-11-26T23:26:24.865821Z","shell.execute_reply":"2025-11-26T23:26:26.357954Z"}},"outputs":[{"name":"stdout","text":"Modelos cargados.\n","output_type":"stream"}],"execution_count":6},{"id":"47e5a354-bf43-43da-be34-2183ed92890a","cell_type":"code","source":"embeddings_sbert = model_sbert.encode(\n    docs,\n    convert_to_numpy=True,\n    show_progress_bar=True,\n    batch_size=64\n)\n\nembeddings_sbert.shape\n","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-11-26T23:26:31.467715Z","iopub.execute_input":"2025-11-26T23:26:31.468055Z","iopub.status.idle":"2025-11-26T23:28:05.537807Z","shell.execute_reply.started":"2025-11-26T23:26:31.468029Z","shell.execute_reply":"2025-11-26T23:28:05.536486Z"}},"outputs":[{"output_type":"display_data","data":{"text/plain":"Batches:   0%|          | 0/32 [00:00<?, ?it/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"3d4c6a3f9e814722ba8efb3a630f94b2"}},"metadata":{}},{"execution_count":7,"output_type":"execute_result","data":{"text/plain":"(2000, 384)"},"metadata":{}}],"execution_count":7},{"id":"c47ee12c-01fd-41d7-b140-eb4477884e6b","cell_type":"code","source":"# E5 requiere agregar \"passage: \" antes de cada documento\ndocs_e5 = [f\"passage: {d}\" for d in docs]\n\nembeddings_e5 = model_e5.encode(\n    docs_e5,\n    convert_to_numpy=True,\n    show_progress_bar=True,\n    batch_size=32\n)\n\nembeddings_e5.shape\n","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-11-26T23:28:14.374266Z","iopub.execute_input":"2025-11-26T23:28:14.375308Z","iopub.status.idle":"2025-11-26T23:42:05.730300Z","shell.execute_reply.started":"2025-11-26T23:28:14.375267Z","shell.execute_reply":"2025-11-26T23:42:05.729333Z"}},"outputs":[{"output_type":"display_data","data":{"text/plain":"Batches:   0%|          | 0/63 [00:00<?, ?it/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"d05d396b616e4d2b95e0060f6e8423e0"}},"metadata":{}},{"execution_count":8,"output_type":"execute_result","data":{"text/plain":"(2000, 768)"},"metadata":{}}],"execution_count":8},{"id":"e9b8efde-634d-4f1c-a558-0ff5b63488fe","cell_type":"code","source":"import numpy as np\nimport os\n\nos.makedirs(\"embeddings\", exist_ok=True)\n\nnp.save(\"embeddings/sbert_embeddings.npy\", embeddings_sbert)\nnp.save(\"embeddings/e5_embeddings.npy\", embeddings_e5)\n\nprint(\"Archivos guardados en la carpeta 'embeddings/'\")\n","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-11-26T23:53:11.635924Z","iopub.execute_input":"2025-11-26T23:53:11.636259Z","iopub.status.idle":"2025-11-26T23:53:11.651748Z","shell.execute_reply.started":"2025-11-26T23:53:11.636237Z","shell.execute_reply":"2025-11-26T23:53:11.649989Z"}},"outputs":[{"name":"stdout","text":"Archivos guardados en la carpeta 'embeddings/'\n","output_type":"stream"}],"execution_count":9},{"id":"ff14fb94-3654-4c20-bb8c-53cba11882c0","cell_type":"code","source":"model_sbert = SentenceTransformer('all-MiniLM-L6-v2', device='cpu')\nmodel_e5 = SentenceTransformer('intfloat/e5-base', device='cpu')","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-11-26T23:53:13.587998Z","iopub.execute_input":"2025-11-26T23:53:13.588356Z","iopub.status.idle":"2025-11-26T23:53:15.179511Z","shell.execute_reply.started":"2025-11-26T23:53:13.588330Z","shell.execute_reply":"2025-11-26T23:53:15.178479Z"}},"outputs":[],"execution_count":10},{"id":"40462a067ca2d379","cell_type":"markdown","source":"## Parte 3: Consulta\n### Actividad\n\n1. Escribe una consulta en lenguaje natural. Ejemplos:\n\n    * \"God, religion, and spirituality\"\n    * \"space exploration\"\n    * \"car maintenance\"\n\n2. Codifica la consulta utilizando el mismo modelo de embeddings. Cuando uses E5, antepon `\"query: \"` a la consulta.\n3. Recupera los 5 documentos más relevantes con similitud coseno.\n4. Muestra los textos de los documentos recuperados (puedes mostrar solo los primeros 500 caracteres de cada uno).","metadata":{}},{"id":"aad085806124c709","cell_type":"code","source":"# Celda robusta: carga/genera embeddings y realiza la consulta + recuperación Top-5\nimport os\nimport numpy as np\nfrom sentence_transformers import SentenceTransformer\nfrom sklearn.metrics.pairwise import cosine_similarity\nfrom sklearn.datasets import fetch_20newsgroups\nimport time\n\n# -------------------------\n# Configuración (AJUSTA si quieres)\n# -------------------------\nmodelo = \"sbert\"   # \"sbert\" o \"e5\"\nN_DOCS = 2000\nTOP_K = 5\nQUERY = \"space exploration\"   # <-- cambia la consulta aquí\nEMB_DIR = \"embeddings\"\nos.makedirs(EMB_DIR, exist_ok=True)\n\n# Posibles rutas de embeddings\npossible_paths = {\n    \"sbert\": [\n        os.path.join(EMB_DIR, \"sbert_embeddings.npy\"),\n        os.path.join(EMB_DIR, \"embeddings_sbert.npy\"),\n        \"embeddings_sbert.npy\",\n        \"embeddings.npy\"\n    ],\n    \"e5\": [\n        os.path.join(EMB_DIR, \"e5_embeddings.npy\"),\n        os.path.join(EMB_DIR, \"embeddings_e5.npy\"),\n        \"embeddings_e5.npy\",\n        \"embeddings.npy\"\n    ]\n}\n\n# -------------------------\n# 1) Cargar corpus si no existe en memoria\n# -------------------------\ntry:\n    # si ya tienes variable en memoria (newsgroupsdocs), úsala\n    newsgroupsdocs\nexcept NameError:\n    newsgroups = fetch_20newsgroups(subset='all', remove=('headers','footers','quotes'))\n    newsgroupsdocs = newsgroups.data\n\ndocs = newsgroupsdocs[:N_DOCS]\nprint(f\"[INFO] Documentos en memoria: {len(docs)} (limitado a {N_DOCS})\")\n\n# -------------------------\n# 2) Buscar archivo de embeddings; si no existe, generarlo\n# -------------------------\ndef find_existing_path(key):\n    for p in possible_paths[key]:\n        if os.path.exists(p):\n            return p\n    return None\n\nemb_path = find_existing_path(modelo)\n\nif emb_path:\n    print(f\"[INFO] Encontrado archivo de embeddings para '{modelo}': {emb_path}\")\n    embeddings = np.load(emb_path)\nelse:\n    print(f\"[INFO] No se encontraron embeddings preguardados para '{modelo}'. Los generaré ahora (CPU).\")\n    # cargar modelo y generar embeddings\n    if modelo == \"sbert\":\n        model_name = \"all-MiniLM-L6-v2\"\n        model = SentenceTransformer(model_name, device=\"cpu\")\n        docs_for_model = docs\n        save_name = os.path.join(EMB_DIR, \"sbert_embeddings.npy\")\n        batch_size = 64\n    else:  # e5\n        model_name = \"intfloat/e5-base\"\n        model = SentenceTransformer(model_name, device=\"cpu\")\n        docs_for_model = [f\"passage: {d}\" for d in docs]\n        save_name = os.path.join(EMB_DIR, \"e5_embeddings.npy\")\n        batch_size = 32\n\n    print(f\"[INFO] Cargando modelo {model_name}...\")\n    t0 = time.time()\n    embeddings = model.encode(docs_for_model, convert_to_numpy=True, show_progress_bar=True, batch_size=batch_size)\n    print(f\"[INFO] Embeddings generados en {time.time()-t0:.1f}s. Shape: {embeddings.shape}\")\n    np.save(save_name, embeddings)\n    print(f\"[INFO] Guardado embeddings en: {save_name}\")\n\n# -------------------------\n# 3) Codificar la consulta (usar prefijo para E5)\n# -------------------------\nif modelo == \"e5\":\n    q_proc = \"query: \" + QUERY\n    model_for_query = SentenceTransformer(\"intfloat/e5-base\", device=\"cpu\")\nelse:\n    q_proc = QUERY\n    model_for_query = SentenceTransformer(\"all-MiniLM-L6-v2\", device=\"cpu\")\n\nprint(f\"[INFO] Codificando consulta con modelo '{modelo}': \\\"{QUERY}\\\"\")\nq_vec = model_for_query.encode([q_proc], convert_to_numpy=True)\n\n# -------------------------\n# 4) Similitud coseno y top-K\n# -------------------------\nsims = cosine_similarity(q_vec, embeddings)[0]\nidxs = sims.argsort()[::-1][:TOP_K]\n\nprint(\"\\n--- Resultados Top-{} ---\".format(TOP_K))\nfor rank, idx in enumerate(idxs, start=1):\n    score = sims[idx]\n    texto = docs[idx]\n    print(f\"\\nRank {rank} | índice {idx} | score {score:.4f}\")\n    print(texto[:500].replace(\"\\n\", \" \") + \"...\")\n","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-11-26T23:53:29.674004Z","iopub.execute_input":"2025-11-26T23:53:29.674680Z","iopub.status.idle":"2025-11-26T23:53:32.728161Z","shell.execute_reply.started":"2025-11-26T23:53:29.674649Z","shell.execute_reply":"2025-11-26T23:53:32.726870Z"}},"outputs":[{"name":"stdout","text":"[INFO] Documentos en memoria: 2000 (limitado a 2000)\n[INFO] Encontrado archivo de embeddings para 'sbert': embeddings/sbert_embeddings.npy\n[INFO] Codificando consulta con modelo 'sbert': \"space exploration\"\n\n--- Resultados Top-5 ---\n\nRank 1 | índice 495 | score 0.4991\nI am posting this for a friend without internet access. Please inquire to the phone number and address listed. ---------------------------------------------------------------------  \"Space: Teaching's Newest Frontier\" Sponsored by the Planetary Studies Foundation  The Planetary Studies Foundation is sponsoring a one week class for teachers called \"Space: Teaching's Newest Frontier.\" The class will be held at the Sheraton Suites in Elk Grove, Illinois from June 14 through June 18. Participants wh...\n\nRank 2 | índice 1643 | score 0.4398\n Well, here goes.  The first item of business is to establish the importance space life sciences in the whole of scheme of humankind.  I mean compared to football and baseball, the average joe schmoe doesn't seem interested or even curious about spaceflight.  I think that this forum can make a major change in that lack of insight and education.  All of us, in our own way, can contribute to a comprehensive document which can be released to the general public around the world.  The document would ...\n\nRank 3 | índice 786 | score 0.4321\nRon Miller is a space artist with a long and distinguished career.   I've admired both his paintings (remember the USPS Solar System Exploration Stamps last year?) and his writings on the history of spaceflight.  For several years he's been working on a *big* project which is almost ready to hit the streets.  A brochure from his publisher has landed in my mailbox, and I thought it was cool enough to type in part of it (it's rather long).  Especially given the Net's strong interest in vaporware s...\n\nRank 4 | índice 1199 | score 0.3995\nAny comments on the absorbtion of the Office of Exploration into the Office of Space Sciences and the reassignment of Griffin to the \"Chief Engineer\" position?  Is this just a meaningless administrative shuffle, or does this bode ill for SEI?  In my opinion, this seems like a Bad Thing, at least on the surface. Griffin seemed to be someone who was actually interested in getting things done, and who was willing to look an innovative approaches to getting things done faster, better, and cheaper.  ...\n\nRank 5 | índice 25 | score 0.3746\nAW&ST  had a brief blurb on a Manned Lunar Exploration confernce May 7th  at Crystal City Virginia, under the auspices of AIAA.  Does anyone know more about this?  How much, to attend????  Anyone want to go?...\n","output_type":"stream"}],"execution_count":12}]}