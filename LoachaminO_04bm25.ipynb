{"metadata":{"kernelspec":{"display_name":"Python 3","language":"python","name":"python3"},"language_info":{"name":"python","version":"3.11.13","mimetype":"text/x-python","codemirror_mode":{"name":"ipython","version":3},"pygments_lexer":"ipython3","nbconvert_exporter":"python","file_extension":".py"},"kaggle":{"accelerator":"none","dataSources":[],"dockerImageVersionId":31192,"isInternetEnabled":true,"language":"python","sourceType":"notebook","isGpuEnabled":false}},"nbformat_minor":5,"nbformat":4,"cells":[{"id":"941741204a003f44","cell_type":"markdown","source":"# Ejercicio 4: Modelo Probabilístico\n\n## Objetivo de la práctica\n- Comprender los componentes del modelo vectorial mediante cálculos manuales y observación directa.\n- Aplicar el modelo de espacio vectorial con TF-IDF para recuperar documentos relevantes.\n- Comparar la recuperación con BM25 frente a TF-IDF.\n- Analizar visualmente las diferencias entre los modelos.\n- Evaluar si los rankings generados son consistentes con lo que considerarías documentos relevantes.","metadata":{}},{"id":"2b057c56-e94d-4d68-b060-d3f29592c462","cell_type":"code","source":"# importacion de librerias\nimport numpy as np\nimport pandas as pd","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-11-13T04:52:12.649392Z","iopub.execute_input":"2025-11-13T04:52:12.649699Z","iopub.status.idle":"2025-11-13T04:52:13.029327Z","shell.execute_reply.started":"2025-11-13T04:52:12.649673Z","shell.execute_reply":"2025-11-13T04:52:13.027984Z"}},"outputs":[],"execution_count":2},{"id":"93bafe7a6a4ef9e5","cell_type":"markdown","source":"## Parte 0: Carga del Corpus","metadata":{}},{"id":"ad08bb8bd43ae327","cell_type":"code","source":"from sklearn.datasets import fetch_20newsgroups\n\nnewsgroups = fetch_20newsgroups(subset='all', remove=('headers', 'footers', 'quotes'))\nnewsgroupsdocs = newsgroups.data","metadata":{"ExecuteTime":{"end_time":"2025-05-28T15:51:00.067230Z","start_time":"2025-05-28T15:49:34.775176Z"},"trusted":true,"execution":{"iopub.status.busy":"2025-11-13T04:52:13.030964Z","iopub.execute_input":"2025-11-13T04:52:13.031364Z","iopub.status.idle":"2025-11-13T04:52:24.393556Z","shell.execute_reply.started":"2025-11-13T04:52:13.031340Z","shell.execute_reply":"2025-11-13T04:52:24.392307Z"}},"outputs":[],"execution_count":3},{"id":"d191a0dd-ba9a-4510-868c-9e2f7ce59f02","cell_type":"markdown","source":"Limpieza del corpus","metadata":{}},{"id":"e29ec6aa-eb0d-45a2-bca0-fa3fa23028ed","cell_type":"code","source":"import re\nfrom sklearn.feature_extraction.text import ENGLISH_STOP_WORDS\n\ndef clean_text(text):\n    # 1. A minúsculas\n    text = text.lower()\n    \n    # 2. Eliminar URLs y correos\n    text = re.sub(r'http\\S+|www\\S+|https\\S+', ' ', text)\n    text = re.sub(r'\\S+@\\S+', ' ', text)\n    \n    # 3. Eliminar caracteres no alfabéticos y convertir a espacios\n    text = re.sub(r'[^a-z\\s]', ' ', text)\n    \n    # 4. Reemplazar múltiples espacios por uno solo\n    text = re.sub(r'\\s+', ' ', text).strip()\n    \n    # 5. Tokenizar\n    tokens = text.split()\n    \n    # 6. Eliminar palabras muy cortas y stopwords\n    tokens = [t for t in tokens if len(t) > 2 and t not in ENGLISH_STOP_WORDS]\n    \n    # 7. Unir de nuevo (opcional, para usar con vectorizers)\n    return ' '.join(tokens)\n\n# Limpieza del corpus completo (puedes probar primero con los primeros 5 documentos)\ncleaned_docs = [clean_text(doc) for doc in newsgroupsdocs]\n\n# Ejemplo de resultado\n#for i, c in enumerate(cleaned_docs):\n#    print(f\"Documento {i} limpio:\\n{c[:400]}\\n{'-'*80}\\n\")\n","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-11-13T04:52:24.395081Z","iopub.execute_input":"2025-11-13T04:52:24.395600Z","iopub.status.idle":"2025-11-13T04:52:28.443310Z","shell.execute_reply.started":"2025-11-13T04:52:24.395572Z","shell.execute_reply":"2025-11-13T04:52:28.442126Z"}},"outputs":[],"execution_count":4},{"id":"ee59bece-9897-4165-b497-73e6e41bc0c5","cell_type":"code","source":"# revision de correcta limpieza\nprint(newsgroupsdocs[0])\nprint(cleaned_docs[0])","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-11-13T04:52:28.445462Z","iopub.execute_input":"2025-11-13T04:52:28.445787Z","iopub.status.idle":"2025-11-13T04:52:28.451627Z","shell.execute_reply.started":"2025-11-13T04:52:28.445760Z","shell.execute_reply":"2025-11-13T04:52:28.450362Z"}},"outputs":[{"name":"stdout","text":"\n\nI am sure some bashers of Pens fans are pretty confused about the lack\nof any kind of posts about the recent Pens massacre of the Devils. Actually,\nI am  bit puzzled too and a bit relieved. However, I am going to put an end\nto non-PIttsburghers' relief with a bit of praise for the Pens. Man, they\nare killing those Devils worse than I thought. Jagr just showed you why\nhe is much better than his regular season stats. He is also a lot\nfo fun to watch in the playoffs. Bowman should let JAgr have a lot of\nfun in the next couple of games since the Pens are going to beat the pulp out of Jersey anyway. I was very disappointed not to see the Islanders lose the final\nregular season game.          PENS RULE!!!\n\n\nsure bashers pens fans pretty confused lack kind posts recent pens massacre devils actually bit puzzled bit relieved going end non pittsburghers relief bit praise pens man killing devils worse thought jagr just showed better regular season stats lot fun watch playoffs bowman let jagr lot fun couple games pens going beat pulp jersey disappointed islanders lose final regular season game pens rule\n","output_type":"stream"}],"execution_count":5},{"id":"c03ec62c-7b12-40b7-9b96-11c04ff1fa35","cell_type":"code","source":"# cantidad de documentos limpiados\nlen(cleaned_docs)","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-11-13T04:52:28.452666Z","iopub.execute_input":"2025-11-13T04:52:28.453230Z","iopub.status.idle":"2025-11-13T04:52:28.480891Z","shell.execute_reply.started":"2025-11-13T04:52:28.453203Z","shell.execute_reply":"2025-11-13T04:52:28.479528Z"}},"outputs":[{"execution_count":6,"output_type":"execute_result","data":{"text/plain":"18846"},"metadata":{}}],"execution_count":6},{"id":"727db055-8942-4cb9-977f-9bc43f115acd","cell_type":"code","source":"# usará corpus, una muestra de los primeros 100 elementos\ncorpus = cleaned_docs[:100]\nlen(corpus)","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-11-13T04:52:28.482029Z","iopub.execute_input":"2025-11-13T04:52:28.482384Z","iopub.status.idle":"2025-11-13T04:52:28.510514Z","shell.execute_reply.started":"2025-11-13T04:52:28.482353Z","shell.execute_reply":"2025-11-13T04:52:28.508818Z"}},"outputs":[{"execution_count":7,"output_type":"execute_result","data":{"text/plain":"100"},"metadata":{}}],"execution_count":7},{"id":"638251eb-7390-4f35-bfad-f2337a8e07d0","cell_type":"code","source":"vocab = sorted(list(set(\" \".join(corpus).split())))\n# vocab = sorted(set(\" \".join(corpus).split()))\nlen(vocab)","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-11-13T04:52:28.511935Z","iopub.execute_input":"2025-11-13T04:52:28.512265Z","iopub.status.idle":"2025-11-13T04:52:28.538079Z","shell.execute_reply.started":"2025-11-13T04:52:28.512241Z","shell.execute_reply":"2025-11-13T04:52:28.536600Z"}},"outputs":[{"execution_count":8,"output_type":"execute_result","data":{"text/plain":"3478"},"metadata":{}}],"execution_count":8},{"id":"2648907e-b138-4704-a85b-a7fc013b07b8","cell_type":"code","source":"print(\"N docs (corpus):\", len(corpus))\nprint(\"Vocab size:\", len(vocab))","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-11-13T04:52:28.539032Z","iopub.execute_input":"2025-11-13T04:52:28.539377Z","iopub.status.idle":"2025-11-13T04:52:28.573183Z","shell.execute_reply.started":"2025-11-13T04:52:28.539348Z","shell.execute_reply":"2025-11-13T04:52:28.572106Z"}},"outputs":[{"name":"stdout","text":"N docs (corpus): 100\nVocab size: 3478\n","output_type":"stream"}],"execution_count":9},{"id":"10f8c7f78934f497","cell_type":"markdown","source":"## Parte 1: Cálculo de TF, DF, IDF y TF-IDF\n\n### Actividad \n1. Utiliza el corpus cargado.\n2. Construye la matriz de términos (TF), y calcula la frecuencia de documentos (DF)\n3. Calcula TF-IDF utilizando sklearn.\n4. Visualiza los valores en un DataFrame para analizar las diferencias entre los términos.","metadata":{}},{"id":"3958ca52-4743-49e5-978a-0e96fbbe8b69","cell_type":"markdown","source":"### Cálculo de TF","metadata":{}},{"id":"cb7b40e1-80af-4aff-8ab2-26a678016528","cell_type":"code","source":"from collections import Counter\n\ndef get_tf_vector(doc, vocab):\n    tokens = doc.split()\n    # Counter se usa temporalmente para acceder fácilmente a los conteos.\n    counts = Counter(tokens)\n    # busca t en el diccionario counts. Si no lo encuentra, devuelve 0\n    return np.array([counts.get(t, 0) for t in vocab], dtype=float)\n\n# construir matriz (n_docs x n_terms)\ntf_matrix = np.array([get_tf_vector(d, vocab) for d in corpus])\ntf_df = pd.DataFrame(tf_matrix, columns=vocab)\n# Mostrar tamaño y primeras filas/columnas\nprint(\"TF matrix shape:\", tf_df.shape)\n#display(tf_df.head())          # muestra primeras 5 filas (documentos) y todas las columnas (puedes desplazarte)\ndisplay(tf_df.head(20))        # por defecto muestra 5 filas, cambié a 20\n","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-11-13T04:52:28.574709Z","iopub.execute_input":"2025-11-13T04:52:28.575123Z","iopub.status.idle":"2025-11-13T04:52:28.727107Z","shell.execute_reply.started":"2025-11-13T04:52:28.575097Z","shell.execute_reply":"2025-11-13T04:52:28.726301Z"}},"outputs":[{"name":"stdout","text":"TF matrix shape: (100, 3478)\n","output_type":"stream"},{"output_type":"display_data","data":{"text/plain":"    aaa  abandoned  abc  abiding  ability  able  absent  accelerated  \\\n0   0.0        0.0  0.0      0.0      0.0   0.0     0.0          0.0   \n1   0.0        0.0  0.0      0.0      0.0   0.0     0.0          0.0   \n2   0.0        0.0  0.0      0.0      0.0   0.0     0.0          0.0   \n3   0.0        0.0  0.0      0.0      1.0   0.0     0.0          0.0   \n4   0.0        0.0  0.0      0.0      0.0   0.0     0.0          0.0   \n5   0.0        0.0  0.0      0.0      0.0   0.0     0.0          0.0   \n6   0.0        0.0  0.0      0.0      0.0   0.0     0.0          0.0   \n7   0.0        0.0  2.0      0.0      0.0   1.0     0.0          0.0   \n8   0.0        0.0  0.0      0.0      0.0   0.0     0.0          0.0   \n9   0.0        0.0  0.0      0.0      0.0   0.0     0.0          0.0   \n10  0.0        0.0  0.0      0.0      0.0   0.0     0.0          0.0   \n11  0.0        0.0  0.0      0.0      0.0   0.0     0.0          0.0   \n12  0.0        1.0  0.0      0.0      2.0   0.0     0.0          0.0   \n13  0.0        0.0  0.0      0.0      0.0   0.0     0.0          0.0   \n14  0.0        0.0  0.0      0.0      0.0   0.0     0.0          0.0   \n15  0.0        0.0  0.0      0.0      0.0   0.0     0.0          0.0   \n16  0.0        0.0  0.0      0.0      0.0   0.0     0.0          0.0   \n17  0.0        0.0  0.0      0.0      0.0   0.0     0.0          0.0   \n18  0.0        0.0  0.0      0.0      0.0   0.0     0.0          0.0   \n19  0.0        0.0  0.0      0.0      0.0   0.0     0.0          0.0   \n\n    accepted  access  ...  young  youth  yvan  yzerman  zalik  zarshad  zeno  \\\n0        0.0     0.0  ...    0.0    0.0   0.0      0.0    0.0      0.0   0.0   \n1        0.0     0.0  ...    0.0    0.0   0.0      0.0    0.0      0.0   0.0   \n2        0.0     0.0  ...    0.0    0.0   0.0      0.0    0.0      0.0   0.0   \n3        0.0     0.0  ...    0.0    0.0   0.0      0.0    0.0      0.0   0.0   \n4        0.0     0.0  ...    0.0    0.0   0.0      0.0    0.0      0.0   0.0   \n5        0.0     0.0  ...    0.0    0.0   0.0      0.0    0.0      0.0   0.0   \n6        0.0     0.0  ...    0.0    0.0   0.0      0.0    0.0      0.0   0.0   \n7        0.0     0.0  ...    0.0    0.0   0.0      0.0    0.0      0.0   0.0   \n8        0.0     0.0  ...    0.0    0.0   0.0      0.0    0.0      0.0   0.0   \n9        0.0     0.0  ...    0.0    0.0   0.0      0.0    0.0      0.0   0.0   \n10       0.0     0.0  ...    0.0    0.0   0.0      0.0    0.0      0.0   0.0   \n11       0.0     0.0  ...    0.0    0.0   0.0      0.0    0.0      0.0   0.0   \n12       0.0     0.0  ...    0.0    0.0   0.0      0.0    0.0      0.0   0.0   \n13       0.0     0.0  ...    0.0    0.0   0.0      0.0    0.0      0.0   0.0   \n14       0.0     0.0  ...    0.0    0.0   0.0      0.0    0.0      0.0   0.0   \n15       0.0     0.0  ...    0.0    0.0   0.0      0.0    0.0      0.0   0.0   \n16       0.0     0.0  ...    0.0    0.0   0.0      0.0    0.0      0.0   0.0   \n17       0.0     0.0  ...    0.0    0.0   0.0      0.0    0.0      0.0   0.0   \n18       1.0     0.0  ...    0.0    0.0   0.0      0.0    0.0      0.0   0.0   \n19       0.0     0.0  ...    0.0    0.0   0.0      0.0    0.0      0.0   0.0   \n\n    zero  zezel  zur  \n0    0.0    0.0  0.0  \n1    0.0    0.0  0.0  \n2    0.0    0.0  0.0  \n3    0.0    0.0  0.0  \n4    0.0    0.0  0.0  \n5    0.0    0.0  0.0  \n6    0.0    0.0  0.0  \n7    0.0    0.0  0.0  \n8    0.0    0.0  0.0  \n9    0.0    0.0  0.0  \n10   0.0    0.0  0.0  \n11   0.0    0.0  0.0  \n12   0.0    0.0  0.0  \n13   0.0    0.0  0.0  \n14   0.0    0.0  0.0  \n15   0.0    0.0  0.0  \n16   0.0    0.0  0.0  \n17   0.0    0.0  0.0  \n18   0.0    0.0  0.0  \n19   0.0    0.0  0.0  \n\n[20 rows x 3478 columns]","text/html":"<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>aaa</th>\n      <th>abandoned</th>\n      <th>abc</th>\n      <th>abiding</th>\n      <th>ability</th>\n      <th>able</th>\n      <th>absent</th>\n      <th>accelerated</th>\n      <th>accepted</th>\n      <th>access</th>\n      <th>...</th>\n      <th>young</th>\n      <th>youth</th>\n      <th>yvan</th>\n      <th>yzerman</th>\n      <th>zalik</th>\n      <th>zarshad</th>\n      <th>zeno</th>\n      <th>zero</th>\n      <th>zezel</th>\n      <th>zur</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>0</th>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>...</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n    </tr>\n    <tr>\n      <th>1</th>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>...</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n    </tr>\n    <tr>\n      <th>2</th>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>...</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n    </tr>\n    <tr>\n      <th>3</th>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>1.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>...</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n    </tr>\n    <tr>\n      <th>4</th>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>...</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n    </tr>\n    <tr>\n      <th>5</th>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>...</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n    </tr>\n    <tr>\n      <th>6</th>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>...</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n    </tr>\n    <tr>\n      <th>7</th>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>2.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>1.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>...</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n    </tr>\n    <tr>\n      <th>8</th>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>...</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n    </tr>\n    <tr>\n      <th>9</th>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>...</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n    </tr>\n    <tr>\n      <th>10</th>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>...</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n    </tr>\n    <tr>\n      <th>11</th>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>...</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n    </tr>\n    <tr>\n      <th>12</th>\n      <td>0.0</td>\n      <td>1.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>2.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>...</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n    </tr>\n    <tr>\n      <th>13</th>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>...</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n    </tr>\n    <tr>\n      <th>14</th>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>...</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n    </tr>\n    <tr>\n      <th>15</th>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>...</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n    </tr>\n    <tr>\n      <th>16</th>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>...</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n    </tr>\n    <tr>\n      <th>17</th>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>...</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n    </tr>\n    <tr>\n      <th>18</th>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>1.0</td>\n      <td>0.0</td>\n      <td>...</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n    </tr>\n    <tr>\n      <th>19</th>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>...</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n    </tr>\n  </tbody>\n</table>\n<p>20 rows × 3478 columns</p>\n</div>"},"metadata":{}}],"execution_count":10},{"id":"18302d60-6018-4bc1-9394-fc09cc97a356","cell_type":"code","source":"corpus[3]","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-11-13T04:52:28.730191Z","iopub.execute_input":"2025-11-13T04:52:28.730494Z","iopub.status.idle":"2025-11-13T04:52:28.738190Z","shell.execute_reply.started":"2025-11-13T04:52:28.730470Z","shell.execute_reply":"2025-11-13T04:52:28.737174Z"}},"outputs":[{"execution_count":11,"output_type":"execute_result","data":{"text/plain":"'think scsi card doing dma transfers disks scsi card dma transfers containing data scsi devices attached wants important feature scsi ability detach device frees scsi bus devices typically used multi tasking start transfers devices device seeking data bus free commands data transfers devices ready transfer data aquire bus send data ide bus start transfer bus busy disk seeked data transfered typically second lock processes wanting bus irrespective transfer time'"},"metadata":{}}],"execution_count":11},{"id":"c453acaa-5ab7-4a5b-aa2c-450805de36bc","cell_type":"markdown","source":"### Cálculo de DF","metadata":{}},{"id":"7a31affe-960f-4209-872a-85db0bbf6207","cell_type":"code","source":"# transforma los elementos > 0 a true (i.e. 1).\ndf_values = (tf_matrix > 0).sum(axis=0)   # vector de longitud vocab\ndf_df = pd.DataFrame({'term': vocab, 'DF': df_values})\n# ordena los terminos de mayor a menor\ndf_df_sorted = df_df.sort_values('DF', ascending=False).reset_index(drop=True)\nprint(\"DF frame shape:\", df_df_sorted.shape)\n# en la lista ya ordenada:\ndisplay(df_df_sorted.head(10))   # muestra los 10 docs más comunes\ndisplay(df_df_sorted.tail(10))   # muestra los 10 docs más raros\n","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-11-13T04:52:28.739194Z","iopub.execute_input":"2025-11-13T04:52:28.739474Z","iopub.status.idle":"2025-11-13T04:52:28.787763Z","shell.execute_reply.started":"2025-11-13T04:52:28.739450Z","shell.execute_reply":"2025-11-13T04:52:28.786813Z"}},"outputs":[{"name":"stdout","text":"DF frame shape: (3478, 2)\n","output_type":"stream"},{"output_type":"display_data","data":{"text/plain":"    term  DF\n0    don  23\n1   know  21\n2   time  20\n3  think  20\n4   just  17\n5   like  16\n6    way  15\n7    use  15\n8   make  14\n9   does  14","text/html":"<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>term</th>\n      <th>DF</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>0</th>\n      <td>don</td>\n      <td>23</td>\n    </tr>\n    <tr>\n      <th>1</th>\n      <td>know</td>\n      <td>21</td>\n    </tr>\n    <tr>\n      <th>2</th>\n      <td>time</td>\n      <td>20</td>\n    </tr>\n    <tr>\n      <th>3</th>\n      <td>think</td>\n      <td>20</td>\n    </tr>\n    <tr>\n      <th>4</th>\n      <td>just</td>\n      <td>17</td>\n    </tr>\n    <tr>\n      <th>5</th>\n      <td>like</td>\n      <td>16</td>\n    </tr>\n    <tr>\n      <th>6</th>\n      <td>way</td>\n      <td>15</td>\n    </tr>\n    <tr>\n      <th>7</th>\n      <td>use</td>\n      <td>15</td>\n    </tr>\n    <tr>\n      <th>8</th>\n      <td>make</td>\n      <td>14</td>\n    </tr>\n    <tr>\n      <th>9</th>\n      <td>does</td>\n      <td>14</td>\n    </tr>\n  </tbody>\n</table>\n</div>"},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"            term  DF\n3468         gvw   1\n3469  gyroscopes   1\n3470       habit   1\n3471         hah   1\n3472    hallmark   1\n3473      handle   1\n3474     handles   1\n3475    handling   1\n3476       hands   1\n3477         zur   1","text/html":"<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>term</th>\n      <th>DF</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>3468</th>\n      <td>gvw</td>\n      <td>1</td>\n    </tr>\n    <tr>\n      <th>3469</th>\n      <td>gyroscopes</td>\n      <td>1</td>\n    </tr>\n    <tr>\n      <th>3470</th>\n      <td>habit</td>\n      <td>1</td>\n    </tr>\n    <tr>\n      <th>3471</th>\n      <td>hah</td>\n      <td>1</td>\n    </tr>\n    <tr>\n      <th>3472</th>\n      <td>hallmark</td>\n      <td>1</td>\n    </tr>\n    <tr>\n      <th>3473</th>\n      <td>handle</td>\n      <td>1</td>\n    </tr>\n    <tr>\n      <th>3474</th>\n      <td>handles</td>\n      <td>1</td>\n    </tr>\n    <tr>\n      <th>3475</th>\n      <td>handling</td>\n      <td>1</td>\n    </tr>\n    <tr>\n      <th>3476</th>\n      <td>hands</td>\n      <td>1</td>\n    </tr>\n    <tr>\n      <th>3477</th>\n      <td>zur</td>\n      <td>1</td>\n    </tr>\n  </tbody>\n</table>\n</div>"},"metadata":{}}],"execution_count":12},{"id":"877e7a9a-1d6f-4c5f-b287-1d52247a3e77","cell_type":"markdown","source":"### Cálculo de IDF","metadata":{}},{"id":"4efd59d2-fb7c-459f-8f62-b0cbb94f4ca8","cell_type":"code","source":"N = len(corpus)\n# evitar DF=0 (no debería haber), pero por seguridad:\ndf_safe = df_values.copy()\ndf_safe[df_safe == 0] = 1\n\n# IDF sin suavizar\nidf_no_smooth = np.log(N / df_safe)\n\n# IDF con suavizado (sklearn-style)\nidf_smooth = np.log((N + 1) / (df_safe + 1)) + 1\n\nidf_df = pd.DataFrame({\n    'term': vocab,\n    'DF': df_values,\n    'IDF_no_smooth': idf_no_smooth,\n    'IDF_smooth': idf_smooth\n}).sort_values('IDF_no_smooth', ascending=False).reset_index(drop=True)\n\ndisplay(idf_df.head(30))   # términos con mayor IDF (términos raros)\n# Calcular TF-IDF manual (usando IDF_no_smooth por ahora)\ntfidf_manual = tf_matrix * idf_smooth  # broadcasting (n_docs x n_terms) * (n_terms,)\ntfidf_df = pd.DataFrame(tfidf_manual, columns=vocab)\nprint(\"Cálculo de TF-IDF, con IDF suavizado (sumando +1 en las ecuaciones de logaritmos).\")\ndisplay(tfidf_df.iloc[:5,:20])   # ver primeras 5 filas y primeras 20 columnas\n","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-11-13T04:52:28.788989Z","iopub.execute_input":"2025-11-13T04:52:28.789260Z","iopub.status.idle":"2025-11-13T04:52:28.844235Z","shell.execute_reply.started":"2025-11-13T04:52:28.789240Z","shell.execute_reply":"2025-11-13T04:52:28.843271Z"}},"outputs":[{"output_type":"display_data","data":{"text/plain":"             term  DF  IDF_no_smooth  IDF_smooth\n0             aaa   1        4.60517    4.921973\n1           pants   1        4.60517    4.921973\n2            ozal   1        4.60517    4.921973\n3           pabon   1        4.60517    4.921973\n4         padover   1        4.60517    4.921973\n5            pads   1        4.60517    4.921973\n6           pages   1        4.60517    4.921973\n7         paiment   1        4.60517    4.921973\n8         painful   1        4.60517    4.921973\n9       pamphlets   1        4.60517    4.921973\n10            pan   1        4.60517    4.921973\n11          papus   1        4.60517    4.921973\n12         oxford   1        4.60517    4.921973\n13        paradox   1        4.60517    4.921973\n14      paragraph   1        4.60517    4.921973\n15     parametric   1        4.60517    4.921973\n16       paranoia   1        4.60517    4.921973\n17   parenthetcal   1        4.60517    4.921973\n18        parents   1        4.60517    4.921973\n19         parity   1        4.60517    4.921973\n20           park   1        4.60517    4.921973\n21  participating   1        4.60517    4.921973\n22         oyster   1        4.60517    4.921973\n23          owner   1        4.60517    4.921973\n24         mullen   1        4.60517    4.921973\n25        osborne   1        4.60517    4.921973\n26   optpublisher   1        4.60517    4.921973\n27       ordained   1        4.60517    4.921973\n28        ordered   1        4.60517    4.921973\n29         orders   1        4.60517    4.921973","text/html":"<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>term</th>\n      <th>DF</th>\n      <th>IDF_no_smooth</th>\n      <th>IDF_smooth</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>0</th>\n      <td>aaa</td>\n      <td>1</td>\n      <td>4.60517</td>\n      <td>4.921973</td>\n    </tr>\n    <tr>\n      <th>1</th>\n      <td>pants</td>\n      <td>1</td>\n      <td>4.60517</td>\n      <td>4.921973</td>\n    </tr>\n    <tr>\n      <th>2</th>\n      <td>ozal</td>\n      <td>1</td>\n      <td>4.60517</td>\n      <td>4.921973</td>\n    </tr>\n    <tr>\n      <th>3</th>\n      <td>pabon</td>\n      <td>1</td>\n      <td>4.60517</td>\n      <td>4.921973</td>\n    </tr>\n    <tr>\n      <th>4</th>\n      <td>padover</td>\n      <td>1</td>\n      <td>4.60517</td>\n      <td>4.921973</td>\n    </tr>\n    <tr>\n      <th>5</th>\n      <td>pads</td>\n      <td>1</td>\n      <td>4.60517</td>\n      <td>4.921973</td>\n    </tr>\n    <tr>\n      <th>6</th>\n      <td>pages</td>\n      <td>1</td>\n      <td>4.60517</td>\n      <td>4.921973</td>\n    </tr>\n    <tr>\n      <th>7</th>\n      <td>paiment</td>\n      <td>1</td>\n      <td>4.60517</td>\n      <td>4.921973</td>\n    </tr>\n    <tr>\n      <th>8</th>\n      <td>painful</td>\n      <td>1</td>\n      <td>4.60517</td>\n      <td>4.921973</td>\n    </tr>\n    <tr>\n      <th>9</th>\n      <td>pamphlets</td>\n      <td>1</td>\n      <td>4.60517</td>\n      <td>4.921973</td>\n    </tr>\n    <tr>\n      <th>10</th>\n      <td>pan</td>\n      <td>1</td>\n      <td>4.60517</td>\n      <td>4.921973</td>\n    </tr>\n    <tr>\n      <th>11</th>\n      <td>papus</td>\n      <td>1</td>\n      <td>4.60517</td>\n      <td>4.921973</td>\n    </tr>\n    <tr>\n      <th>12</th>\n      <td>oxford</td>\n      <td>1</td>\n      <td>4.60517</td>\n      <td>4.921973</td>\n    </tr>\n    <tr>\n      <th>13</th>\n      <td>paradox</td>\n      <td>1</td>\n      <td>4.60517</td>\n      <td>4.921973</td>\n    </tr>\n    <tr>\n      <th>14</th>\n      <td>paragraph</td>\n      <td>1</td>\n      <td>4.60517</td>\n      <td>4.921973</td>\n    </tr>\n    <tr>\n      <th>15</th>\n      <td>parametric</td>\n      <td>1</td>\n      <td>4.60517</td>\n      <td>4.921973</td>\n    </tr>\n    <tr>\n      <th>16</th>\n      <td>paranoia</td>\n      <td>1</td>\n      <td>4.60517</td>\n      <td>4.921973</td>\n    </tr>\n    <tr>\n      <th>17</th>\n      <td>parenthetcal</td>\n      <td>1</td>\n      <td>4.60517</td>\n      <td>4.921973</td>\n    </tr>\n    <tr>\n      <th>18</th>\n      <td>parents</td>\n      <td>1</td>\n      <td>4.60517</td>\n      <td>4.921973</td>\n    </tr>\n    <tr>\n      <th>19</th>\n      <td>parity</td>\n      <td>1</td>\n      <td>4.60517</td>\n      <td>4.921973</td>\n    </tr>\n    <tr>\n      <th>20</th>\n      <td>park</td>\n      <td>1</td>\n      <td>4.60517</td>\n      <td>4.921973</td>\n    </tr>\n    <tr>\n      <th>21</th>\n      <td>participating</td>\n      <td>1</td>\n      <td>4.60517</td>\n      <td>4.921973</td>\n    </tr>\n    <tr>\n      <th>22</th>\n      <td>oyster</td>\n      <td>1</td>\n      <td>4.60517</td>\n      <td>4.921973</td>\n    </tr>\n    <tr>\n      <th>23</th>\n      <td>owner</td>\n      <td>1</td>\n      <td>4.60517</td>\n      <td>4.921973</td>\n    </tr>\n    <tr>\n      <th>24</th>\n      <td>mullen</td>\n      <td>1</td>\n      <td>4.60517</td>\n      <td>4.921973</td>\n    </tr>\n    <tr>\n      <th>25</th>\n      <td>osborne</td>\n      <td>1</td>\n      <td>4.60517</td>\n      <td>4.921973</td>\n    </tr>\n    <tr>\n      <th>26</th>\n      <td>optpublisher</td>\n      <td>1</td>\n      <td>4.60517</td>\n      <td>4.921973</td>\n    </tr>\n    <tr>\n      <th>27</th>\n      <td>ordained</td>\n      <td>1</td>\n      <td>4.60517</td>\n      <td>4.921973</td>\n    </tr>\n    <tr>\n      <th>28</th>\n      <td>ordered</td>\n      <td>1</td>\n      <td>4.60517</td>\n      <td>4.921973</td>\n    </tr>\n    <tr>\n      <th>29</th>\n      <td>orders</td>\n      <td>1</td>\n      <td>4.60517</td>\n      <td>4.921973</td>\n    </tr>\n  </tbody>\n</table>\n</div>"},"metadata":{}},{"name":"stdout","text":"Cálculo de TF-IDF, con IDF suavizado (sumando +1 en las ecuaciones de logaritmos).\n","output_type":"stream"},{"output_type":"display_data","data":{"text/plain":"   aaa  abandoned  abc  abiding  ability  able  absent  accelerated  accepted  \\\n0  0.0        0.0  0.0      0.0  0.00000   0.0     0.0          0.0       0.0   \n1  0.0        0.0  0.0      0.0  0.00000   0.0     0.0          0.0       0.0   \n2  0.0        0.0  0.0      0.0  0.00000   0.0     0.0          0.0       0.0   \n3  0.0        0.0  0.0      0.0  3.66921   0.0     0.0          0.0       0.0   \n4  0.0        0.0  0.0      0.0  0.00000   0.0     0.0          0.0       0.0   \n\n   access  accident  according  accurate  accused  acetone  achieved  achkar  \\\n0     0.0       0.0        0.0       0.0      0.0      0.0       0.0     0.0   \n1     0.0       0.0        0.0       0.0      0.0      0.0       0.0     0.0   \n2     0.0       0.0        0.0       0.0      0.0      0.0       0.0     0.0   \n3     0.0       0.0        0.0       0.0      0.0      0.0       0.0     0.0   \n4     0.0       0.0        0.0       0.0      0.0      0.0       0.0     0.0   \n\n   acknowledges  aclu  acquiring  \n0           0.0   0.0        0.0  \n1           0.0   0.0        0.0  \n2           0.0   0.0        0.0  \n3           0.0   0.0        0.0  \n4           0.0   0.0        0.0  ","text/html":"<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>aaa</th>\n      <th>abandoned</th>\n      <th>abc</th>\n      <th>abiding</th>\n      <th>ability</th>\n      <th>able</th>\n      <th>absent</th>\n      <th>accelerated</th>\n      <th>accepted</th>\n      <th>access</th>\n      <th>accident</th>\n      <th>according</th>\n      <th>accurate</th>\n      <th>accused</th>\n      <th>acetone</th>\n      <th>achieved</th>\n      <th>achkar</th>\n      <th>acknowledges</th>\n      <th>aclu</th>\n      <th>acquiring</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>0</th>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.00000</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n    </tr>\n    <tr>\n      <th>1</th>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.00000</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n    </tr>\n    <tr>\n      <th>2</th>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.00000</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n    </tr>\n    <tr>\n      <th>3</th>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>3.66921</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n    </tr>\n    <tr>\n      <th>4</th>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.00000</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n    </tr>\n  </tbody>\n</table>\n</div>"},"metadata":{}}],"execution_count":13},{"id":"a4071bf8-9567-4bc4-bd12-f0d6b69eb47e","cell_type":"markdown","source":"### Cálculo de TF-IDF con sklearn","metadata":{}},{"id":"3d387ae0-6718-406e-bc0f-da76f96dd071","cell_type":"code","source":"from sklearn.feature_extraction.text import TfidfVectorizer\n\n# Vectorizer con suavizado (sklearn default: smooth_idf=True). No normalizamos (norm=None) para ser comparable.\nvec_sklearn = TfidfVectorizer(vocabulary=vocab, use_idf=True, smooth_idf=True, norm=None, token_pattern=r\"(?u)\\b\\w+\\b\")\nX_sklearn = vec_sklearn.fit_transform(corpus)   # shape (N, V)\nidf_sklearn = vec_sklearn.idf_    # len = V\n\n# DataFrame comparativo IDF\ncomp_idf_df = pd.DataFrame({\n    'term': vec_sklearn.get_feature_names_out(),\n    'IDF_sklearn': idf_sklearn,\n    'IDF_manual_smooth': idf_smooth\n})\n# mostrar primeras filas y comparar\ndisplay(comp_idf_df.sort_values('IDF_sklearn', ascending=False).head(30))\n# convertir matriz sklearn a DataFrame (con cuidado de memoria)\ntfidf_sklearn_df = pd.DataFrame(X_sklearn.toarray(), columns=vec_sklearn.get_feature_names_out())\ndisplay(tfidf_sklearn_df.iloc[:5,:20])\n","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-11-13T04:52:28.845448Z","iopub.execute_input":"2025-11-13T04:52:28.845820Z","iopub.status.idle":"2025-11-13T04:52:28.906487Z","shell.execute_reply.started":"2025-11-13T04:52:28.845788Z","shell.execute_reply":"2025-11-13T04:52:28.905256Z"}},"outputs":[{"output_type":"display_data","data":{"text/plain":"               term  IDF_sklearn  IDF_manual_smooth\n0               aaa     4.921973           4.921973\n2164          pants     4.921973           4.921973\n2151           ozal     4.921973           4.921973\n2152          pabon     4.921973           4.921973\n2154        padover     4.921973           4.921973\n2155           pads     4.921973           4.921973\n2156          pages     4.921973           4.921973\n2158        paiment     4.921973           4.921973\n2160        painful     4.921973           4.921973\n2162      pamphlets     4.921973           4.921973\n2163            pan     4.921973           4.921973\n2167          papus     4.921973           4.921973\n2149         oxford     4.921973           4.921973\n2168        paradox     4.921973           4.921973\n2169      paragraph     4.921973           4.921973\n2171     parametric     4.921973           4.921973\n2172       paranoia     4.921973           4.921973\n2173   parenthetcal     4.921973           4.921973\n2174        parents     4.921973           4.921973\n2175         parity     4.921973           4.921973\n2176           park     4.921973           4.921973\n2178  participating     4.921973           4.921973\n2150         oyster     4.921973           4.921973\n2148          owner     4.921973           4.921973\n1995         mullen     4.921973           4.921973\n2136        osborne     4.921973           4.921973\n2123   optpublisher     4.921973           4.921973\n2125       ordained     4.921973           4.921973\n2127        ordered     4.921973           4.921973\n2128         orders     4.921973           4.921973","text/html":"<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>term</th>\n      <th>IDF_sklearn</th>\n      <th>IDF_manual_smooth</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>0</th>\n      <td>aaa</td>\n      <td>4.921973</td>\n      <td>4.921973</td>\n    </tr>\n    <tr>\n      <th>2164</th>\n      <td>pants</td>\n      <td>4.921973</td>\n      <td>4.921973</td>\n    </tr>\n    <tr>\n      <th>2151</th>\n      <td>ozal</td>\n      <td>4.921973</td>\n      <td>4.921973</td>\n    </tr>\n    <tr>\n      <th>2152</th>\n      <td>pabon</td>\n      <td>4.921973</td>\n      <td>4.921973</td>\n    </tr>\n    <tr>\n      <th>2154</th>\n      <td>padover</td>\n      <td>4.921973</td>\n      <td>4.921973</td>\n    </tr>\n    <tr>\n      <th>2155</th>\n      <td>pads</td>\n      <td>4.921973</td>\n      <td>4.921973</td>\n    </tr>\n    <tr>\n      <th>2156</th>\n      <td>pages</td>\n      <td>4.921973</td>\n      <td>4.921973</td>\n    </tr>\n    <tr>\n      <th>2158</th>\n      <td>paiment</td>\n      <td>4.921973</td>\n      <td>4.921973</td>\n    </tr>\n    <tr>\n      <th>2160</th>\n      <td>painful</td>\n      <td>4.921973</td>\n      <td>4.921973</td>\n    </tr>\n    <tr>\n      <th>2162</th>\n      <td>pamphlets</td>\n      <td>4.921973</td>\n      <td>4.921973</td>\n    </tr>\n    <tr>\n      <th>2163</th>\n      <td>pan</td>\n      <td>4.921973</td>\n      <td>4.921973</td>\n    </tr>\n    <tr>\n      <th>2167</th>\n      <td>papus</td>\n      <td>4.921973</td>\n      <td>4.921973</td>\n    </tr>\n    <tr>\n      <th>2149</th>\n      <td>oxford</td>\n      <td>4.921973</td>\n      <td>4.921973</td>\n    </tr>\n    <tr>\n      <th>2168</th>\n      <td>paradox</td>\n      <td>4.921973</td>\n      <td>4.921973</td>\n    </tr>\n    <tr>\n      <th>2169</th>\n      <td>paragraph</td>\n      <td>4.921973</td>\n      <td>4.921973</td>\n    </tr>\n    <tr>\n      <th>2171</th>\n      <td>parametric</td>\n      <td>4.921973</td>\n      <td>4.921973</td>\n    </tr>\n    <tr>\n      <th>2172</th>\n      <td>paranoia</td>\n      <td>4.921973</td>\n      <td>4.921973</td>\n    </tr>\n    <tr>\n      <th>2173</th>\n      <td>parenthetcal</td>\n      <td>4.921973</td>\n      <td>4.921973</td>\n    </tr>\n    <tr>\n      <th>2174</th>\n      <td>parents</td>\n      <td>4.921973</td>\n      <td>4.921973</td>\n    </tr>\n    <tr>\n      <th>2175</th>\n      <td>parity</td>\n      <td>4.921973</td>\n      <td>4.921973</td>\n    </tr>\n    <tr>\n      <th>2176</th>\n      <td>park</td>\n      <td>4.921973</td>\n      <td>4.921973</td>\n    </tr>\n    <tr>\n      <th>2178</th>\n      <td>participating</td>\n      <td>4.921973</td>\n      <td>4.921973</td>\n    </tr>\n    <tr>\n      <th>2150</th>\n      <td>oyster</td>\n      <td>4.921973</td>\n      <td>4.921973</td>\n    </tr>\n    <tr>\n      <th>2148</th>\n      <td>owner</td>\n      <td>4.921973</td>\n      <td>4.921973</td>\n    </tr>\n    <tr>\n      <th>1995</th>\n      <td>mullen</td>\n      <td>4.921973</td>\n      <td>4.921973</td>\n    </tr>\n    <tr>\n      <th>2136</th>\n      <td>osborne</td>\n      <td>4.921973</td>\n      <td>4.921973</td>\n    </tr>\n    <tr>\n      <th>2123</th>\n      <td>optpublisher</td>\n      <td>4.921973</td>\n      <td>4.921973</td>\n    </tr>\n    <tr>\n      <th>2125</th>\n      <td>ordained</td>\n      <td>4.921973</td>\n      <td>4.921973</td>\n    </tr>\n    <tr>\n      <th>2127</th>\n      <td>ordered</td>\n      <td>4.921973</td>\n      <td>4.921973</td>\n    </tr>\n    <tr>\n      <th>2128</th>\n      <td>orders</td>\n      <td>4.921973</td>\n      <td>4.921973</td>\n    </tr>\n  </tbody>\n</table>\n</div>"},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"   aaa  abandoned  abc  abiding  ability  able  absent  accelerated  accepted  \\\n0  0.0        0.0  0.0      0.0  0.00000   0.0     0.0          0.0       0.0   \n1  0.0        0.0  0.0      0.0  0.00000   0.0     0.0          0.0       0.0   \n2  0.0        0.0  0.0      0.0  0.00000   0.0     0.0          0.0       0.0   \n3  0.0        0.0  0.0      0.0  3.66921   0.0     0.0          0.0       0.0   \n4  0.0        0.0  0.0      0.0  0.00000   0.0     0.0          0.0       0.0   \n\n   access  accident  according  accurate  accused  acetone  achieved  achkar  \\\n0     0.0       0.0        0.0       0.0      0.0      0.0       0.0     0.0   \n1     0.0       0.0        0.0       0.0      0.0      0.0       0.0     0.0   \n2     0.0       0.0        0.0       0.0      0.0      0.0       0.0     0.0   \n3     0.0       0.0        0.0       0.0      0.0      0.0       0.0     0.0   \n4     0.0       0.0        0.0       0.0      0.0      0.0       0.0     0.0   \n\n   acknowledges  aclu  acquiring  \n0           0.0   0.0        0.0  \n1           0.0   0.0        0.0  \n2           0.0   0.0        0.0  \n3           0.0   0.0        0.0  \n4           0.0   0.0        0.0  ","text/html":"<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>aaa</th>\n      <th>abandoned</th>\n      <th>abc</th>\n      <th>abiding</th>\n      <th>ability</th>\n      <th>able</th>\n      <th>absent</th>\n      <th>accelerated</th>\n      <th>accepted</th>\n      <th>access</th>\n      <th>accident</th>\n      <th>according</th>\n      <th>accurate</th>\n      <th>accused</th>\n      <th>acetone</th>\n      <th>achieved</th>\n      <th>achkar</th>\n      <th>acknowledges</th>\n      <th>aclu</th>\n      <th>acquiring</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>0</th>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.00000</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n    </tr>\n    <tr>\n      <th>1</th>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.00000</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n    </tr>\n    <tr>\n      <th>2</th>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.00000</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n    </tr>\n    <tr>\n      <th>3</th>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>3.66921</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n    </tr>\n    <tr>\n      <th>4</th>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.00000</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n    </tr>\n  </tbody>\n</table>\n</div>"},"metadata":{}}],"execution_count":14},{"id":"fed32bf8-331a-4a82-8ec8-8f7a2addc27f","cell_type":"markdown","source":"comparacion ability del doc 3","metadata":{}},{"id":"05b75435-815a-417a-a33f-610f590a94af","cell_type":"code","source":"# análisis de ability en el doc 3\nterm = 'ability'\nif term in vocab:\n    idx = vocab.index(term)\n    doc_idx = 3\n    tf = tf_matrix[doc_idx, idx]\n    df = df_values[idx]\n    print(\"TF (doc,term):\", tf)\n    print(\"DF (term):\", df)\n    print(\"N:\", N)\n    print(\"IDF no smooth:\", idf_no_smooth[idx])\n    print(\"IDF smooth  :\", idf_smooth[idx])\n    print(\"TF-IDF manual (no smooth):\", tf * idf_no_smooth[idx])\n    print(\"TF-IDF sklearn (smooth):   \", tfidf_sklearn_df.iloc[doc_idx, idx])\nelse:\n    print(\"Term not in vocab\")\n","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-11-13T04:52:28.907573Z","iopub.execute_input":"2025-11-13T04:52:28.907889Z","iopub.status.idle":"2025-11-13T04:52:28.916365Z","shell.execute_reply.started":"2025-11-13T04:52:28.907866Z","shell.execute_reply":"2025-11-13T04:52:28.915160Z"}},"outputs":[{"name":"stdout","text":"TF (doc,term): 1.0\nDF (term): 6\nN: 100\nIDF no smooth: 2.8134107167600364\nIDF smooth  : 3.6692103677859462\nTF-IDF manual (no smooth): 2.8134107167600364\nTF-IDF sklearn (smooth):    3.6692103677859462\n","output_type":"stream"}],"execution_count":15},{"id":"64491bce5361e8b3","cell_type":"markdown","source":"## Parte 2: Ranking de documentos usando TF-IDF\n\n### Actividad \n\n1. Dada una consulta, construye el vector de consulta\n2. Calcula la similitud coseno entre la consulta y cada documento usando los vectores TF-IDF\n3. Genera un ranking de los documentos ordenados por relevancia.\n4. Muestra los resultados en una tabla.","metadata":{}},{"id":"18ff93fd-c4f3-4921-9625-a1c665d1b6fb","cell_type":"markdown","source":"### Construcción del vector consulta","metadata":{}},{"id":"e6651681-bb56-4761-95e8-f9c55a876fc7","cell_type":"code","source":"# se crea la consulta\n# query = \"pens hockey playoff abandoned\"\n# query = \"pens hockey playoff\"\nquery = 'question comes frequently faq aaa'\n# query = 'years ago victim squirted fair old model'\nquery_clean = clean_text(query)\nprint(\"Query limpia:\", query_clean)\n\n# Calcular TF de la consulta\ntf_query = get_tf_vector(query_clean, vocab)\nprint(\"TF (query) - número de términos no nulos:\", int(np.sum(tf_query > 0)))\n\nprint(\"\\nRepresentación en Texto:\")\n\n# Mostrar términos no nulos con su TF\nnonzero_idx = np.where(tf_query > 0)[0]\nprint(\"\\nTérminos y TF en la query:\")\nfor i in nonzero_idx:\n    print(f\"  {vocab[i]} : TF = {int(tf_query[i])}\")\n\n# Calcular TF-IDF de la consulta\ntfidf_query = tf_query * idf_smooth\n\n# Mostrar términos con su TF-IDF\nprint(\"\\nTérminos y TF-IDF (query):\")\nfor i in nonzero_idx:\n    print(f\"  {vocab[i]} : TF-IDF = {tfidf_query[i]:.6f}\")\n\n\n# construir matriz (1 x n_terms)\ntf_matrix_query = np.array([tf_query])\ntf_df_query = pd.DataFrame(tf_matrix_query, columns=vocab)\n\nprint(\"\\nRepresentación en DataFrames:\")\n\n# Mostrar tamaño y primeras columnas\nprint(\"\\nTF matrix (query) shape:\", tf_df_query.shape)\ndisplay(tf_df_query.iloc[:, :20])  # muestra las primeras 20 columnas\n# Filtrar solo las columnas con TF > 0\nprint(\"\\nTF matrix (query): solo elementos no nulos\")\nnonzero_cols = tf_df_query.loc[:, (tf_df_query != 0).any(axis=0)]\ndisplay(nonzero_cols)\n\n\n# --- (Opcional) matriz TF-IDF también ---\ntfidf_df_query = pd.DataFrame([tfidf_query], columns=vocab)\nprint(\"\\nTF-IDF matrix (query) shape:\", tfidf_df_query.shape)\ndisplay(tfidf_df_query.iloc[:, :20])\n# Filtrar solo las columnas con TF-IDF > 0\nprint(\"\\nTF-IDF matrix (query): solo elementos no nulos\")\nnonzero_cols_tfidf = tfidf_df_query.loc[:, (tfidf_df_query != 0).any(axis=0)]\ndisplay(nonzero_cols_tfidf)\n","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-11-13T04:52:29.873526Z","iopub.execute_input":"2025-11-13T04:52:29.873855Z","iopub.status.idle":"2025-11-13T04:52:30.035939Z","shell.execute_reply.started":"2025-11-13T04:52:29.873824Z","shell.execute_reply":"2025-11-13T04:52:30.034397Z"}},"outputs":[{"name":"stdout","text":"Query limpia: question comes frequently faq aaa\nTF (query) - número de términos no nulos: 5\n\nRepresentación en Texto:\n\nTérminos y TF en la query:\n  aaa : TF = 1\n  comes : TF = 1\n  faq : TF = 1\n  frequently : TF = 1\n  question : TF = 1\n\nTérminos y TF-IDF (query):\n  aaa : TF-IDF = 4.921973\n  comes : TF-IDF = 4.005683\n  faq : TF-IDF = 4.516508\n  frequently : TF-IDF = 4.516508\n  question : TF-IDF = 3.417896\n\nRepresentación en DataFrames:\n\nTF matrix (query) shape: (1, 3478)\n","output_type":"stream"},{"output_type":"display_data","data":{"text/plain":"   aaa  abandoned  abc  abiding  ability  able  absent  accelerated  accepted  \\\n0  1.0        0.0  0.0      0.0      0.0   0.0     0.0          0.0       0.0   \n\n   access  accident  according  accurate  accused  acetone  achieved  achkar  \\\n0     0.0       0.0        0.0       0.0      0.0      0.0       0.0     0.0   \n\n   acknowledges  aclu  acquiring  \n0           0.0   0.0        0.0  ","text/html":"<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>aaa</th>\n      <th>abandoned</th>\n      <th>abc</th>\n      <th>abiding</th>\n      <th>ability</th>\n      <th>able</th>\n      <th>absent</th>\n      <th>accelerated</th>\n      <th>accepted</th>\n      <th>access</th>\n      <th>accident</th>\n      <th>according</th>\n      <th>accurate</th>\n      <th>accused</th>\n      <th>acetone</th>\n      <th>achieved</th>\n      <th>achkar</th>\n      <th>acknowledges</th>\n      <th>aclu</th>\n      <th>acquiring</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>0</th>\n      <td>1.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n    </tr>\n  </tbody>\n</table>\n</div>"},"metadata":{}},{"name":"stdout","text":"\nTF matrix (query): solo elementos no nulos\n","output_type":"stream"},{"output_type":"display_data","data":{"text/plain":"   aaa  comes  faq  frequently  question\n0  1.0    1.0  1.0         1.0       1.0","text/html":"<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>aaa</th>\n      <th>comes</th>\n      <th>faq</th>\n      <th>frequently</th>\n      <th>question</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>0</th>\n      <td>1.0</td>\n      <td>1.0</td>\n      <td>1.0</td>\n      <td>1.0</td>\n      <td>1.0</td>\n    </tr>\n  </tbody>\n</table>\n</div>"},"metadata":{}},{"name":"stdout","text":"\nTF-IDF matrix (query) shape: (1, 3478)\n","output_type":"stream"},{"output_type":"display_data","data":{"text/plain":"        aaa  abandoned  abc  abiding  ability  able  absent  accelerated  \\\n0  4.921973        0.0  0.0      0.0      0.0   0.0     0.0          0.0   \n\n   accepted  access  accident  according  accurate  accused  acetone  \\\n0       0.0     0.0       0.0        0.0       0.0      0.0      0.0   \n\n   achieved  achkar  acknowledges  aclu  acquiring  \n0       0.0     0.0           0.0   0.0        0.0  ","text/html":"<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>aaa</th>\n      <th>abandoned</th>\n      <th>abc</th>\n      <th>abiding</th>\n      <th>ability</th>\n      <th>able</th>\n      <th>absent</th>\n      <th>accelerated</th>\n      <th>accepted</th>\n      <th>access</th>\n      <th>accident</th>\n      <th>according</th>\n      <th>accurate</th>\n      <th>accused</th>\n      <th>acetone</th>\n      <th>achieved</th>\n      <th>achkar</th>\n      <th>acknowledges</th>\n      <th>aclu</th>\n      <th>acquiring</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>0</th>\n      <td>4.921973</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n    </tr>\n  </tbody>\n</table>\n</div>"},"metadata":{}},{"name":"stdout","text":"\nTF-IDF matrix (query): solo elementos no nulos\n","output_type":"stream"},{"output_type":"display_data","data":{"text/plain":"        aaa     comes       faq  frequently  question\n0  4.921973  4.005683  4.516508    4.516508  3.417896","text/html":"<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>aaa</th>\n      <th>comes</th>\n      <th>faq</th>\n      <th>frequently</th>\n      <th>question</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>0</th>\n      <td>4.921973</td>\n      <td>4.005683</td>\n      <td>4.516508</td>\n      <td>4.516508</td>\n      <td>3.417896</td>\n    </tr>\n  </tbody>\n</table>\n</div>"},"metadata":{}}],"execution_count":28},{"id":"4d4126dc-3af8-44ca-b91d-26aedbeff16b","cell_type":"markdown","source":"### Similitud Coseno","metadata":{}},{"id":"6f9c2c75-c417-419b-aaaa-c4f0f011b72f","cell_type":"code","source":"# Normalizar vectores TF-IDF\n# produce un vector de longitud igual al número de documentos en el corpus\n# Sim(q, d1), Sim(q, d2), ..., Sim(q, dn); n = totDocumentos\ndef cosine_similarity_manual(query_vec, docs_matrix):\n    similarities = []\n    norm_q = np.linalg.norm(query_vec)\n    \n    for d in docs_matrix:\n        norm_d = np.linalg.norm(d)\n        if norm_d == 0 or norm_q == 0:\n            similarities.append(0.0)\n        else:\n            sim = np.dot(query_vec, d) / (norm_q * norm_d)\n            similarities.append(sim)\n    return np.array(similarities)\n\n# Calcular similitudes\nsimilarities_manual = cosine_similarity_manual(tfidf_query, tfidf_manual)\n\n# Crear DataFrame con una columna\nsimilarities_manual_df = pd.DataFrame({\n    'doc_id': np.arange(len(similarities_manual)),\n    'similarity': similarities_manual\n})\n\n# Mostrar ordenado por similitud descendente\nsimilarities_manual_df_sorted = similarities_manual_df.sort_values('similarity', ascending=False).reset_index(drop=True)\n\nprint(\"Máxima similitud:\", np.max(similarities_manual))\nprint(\"Cantidad de documentos con similitud > 0:\", np.sum(similarities_manual > 0))\n\ndisplay(similarities_manual_df_sorted.head(10))","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-11-13T04:52:30.039714Z","iopub.execute_input":"2025-11-13T04:52:30.040091Z","iopub.status.idle":"2025-11-13T04:52:30.065396Z","shell.execute_reply.started":"2025-11-13T04:52:30.040065Z","shell.execute_reply":"2025-11-13T04:52:30.064272Z"}},"outputs":[{"name":"stdout","text":"Máxima similitud: 0.8595394304317006\nCantidad de documentos con similitud > 0: 12\n","output_type":"stream"},{"output_type":"display_data","data":{"text/plain":"   doc_id  similarity\n0      73    0.859539\n1      13    0.111335\n2      96    0.091322\n3      45    0.080147\n4      29    0.066777\n5      77    0.063931\n6      60    0.059890\n7      97    0.037775\n8       4    0.034865\n9      86    0.027034","text/html":"<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>doc_id</th>\n      <th>similarity</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>0</th>\n      <td>73</td>\n      <td>0.859539</td>\n    </tr>\n    <tr>\n      <th>1</th>\n      <td>13</td>\n      <td>0.111335</td>\n    </tr>\n    <tr>\n      <th>2</th>\n      <td>96</td>\n      <td>0.091322</td>\n    </tr>\n    <tr>\n      <th>3</th>\n      <td>45</td>\n      <td>0.080147</td>\n    </tr>\n    <tr>\n      <th>4</th>\n      <td>29</td>\n      <td>0.066777</td>\n    </tr>\n    <tr>\n      <th>5</th>\n      <td>77</td>\n      <td>0.063931</td>\n    </tr>\n    <tr>\n      <th>6</th>\n      <td>60</td>\n      <td>0.059890</td>\n    </tr>\n    <tr>\n      <th>7</th>\n      <td>97</td>\n      <td>0.037775</td>\n    </tr>\n    <tr>\n      <th>8</th>\n      <td>4</td>\n      <td>0.034865</td>\n    </tr>\n    <tr>\n      <th>9</th>\n      <td>86</td>\n      <td>0.027034</td>\n    </tr>\n  </tbody>\n</table>\n</div>"},"metadata":{}}],"execution_count":29},{"id":"c96d6c30-3ca6-4c3b-a9a5-0cc14221afa9","cell_type":"markdown","source":"### Ranking de documentos\nOrdenados por Relevancia. El más relevante es aquel que tiene una similitud mayor entre query y documento.","metadata":{}},{"id":"b93c2c8d-1e4e-4697-a95f-7b725cbdfcc2","cell_type":"code","source":"# Crear tabla de resultados\nranking_manual = pd.DataFrame({\n    'doc_id': range(len(corpus)),\n    'similarity': similarities_manual,\n    'text_preview': [doc[:200].replace('\\n', ' ') + '...' for doc in corpus]\n})\n\n# Ordenar por mayor similitud\nranking_manual = ranking_manual.sort_values('similarity', ascending=False).reset_index(drop=True)\n\n# Mostrar los 3 primeros resultados\nranking_manual.head(3)","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-11-13T04:52:30.066520Z","iopub.execute_input":"2025-11-13T04:52:30.066977Z","iopub.status.idle":"2025-11-13T04:52:30.101542Z","shell.execute_reply.started":"2025-11-13T04:52:30.066949Z","shell.execute_reply":"2025-11-13T04:52:30.100220Z"}},"outputs":[{"execution_count":30,"output_type":"execute_result","data":{"text/plain":"   doc_id  similarity                                       text_preview\n0      73    0.859539                   question comes frequently faq...\n1      13    0.111335  kirlian imaging believe faq sci skeptics nice ...\n2      96    0.091322  question year mail order notebook meg ram prob...","text/html":"<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>doc_id</th>\n      <th>similarity</th>\n      <th>text_preview</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>0</th>\n      <td>73</td>\n      <td>0.859539</td>\n      <td>question comes frequently faq...</td>\n    </tr>\n    <tr>\n      <th>1</th>\n      <td>13</td>\n      <td>0.111335</td>\n      <td>kirlian imaging believe faq sci skeptics nice ...</td>\n    </tr>\n    <tr>\n      <th>2</th>\n      <td>96</td>\n      <td>0.091322</td>\n      <td>question year mail order notebook meg ram prob...</td>\n    </tr>\n  </tbody>\n</table>\n</div>"},"metadata":{}}],"execution_count":30},{"id":"17b12ef9-1553-4bac-935b-7f6f2c558820","cell_type":"code","source":"top_doc_id = ranking_manual.iloc[0]['doc_id']\nprint(f\"Documento más relevante (ID={top_doc_id}):\\n\")\nprint(corpus[top_doc_id])\n","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-11-13T04:59:36.060669Z","iopub.execute_input":"2025-11-13T04:59:36.061047Z","iopub.status.idle":"2025-11-13T04:59:36.068141Z","shell.execute_reply.started":"2025-11-13T04:59:36.061024Z","shell.execute_reply":"2025-11-13T04:59:36.066634Z"}},"outputs":[{"name":"stdout","text":"Documento más relevante (ID=73):\n\nquestion comes frequently faq\n","output_type":"stream"}],"execution_count":31},{"id":"97061325508dc5f2","cell_type":"markdown","source":"## Parte 3: Ranking con BM25\n\n### Actividad \n\n1. Implementa un sistema de recuperación usando el modelo BM25.\n2. Usa la misma consulta del ejercicio anterior.\n3. Calcula el score BM25 para cada documento y genera un ranking.\n4. Compara manualmente con el ranking de TF-IDF.","metadata":{}},{"id":"2a0dca2bcfa73c5b","cell_type":"code","source":"# Pendiente de implementación (BM25)","metadata":{"trusted":true},"outputs":[],"execution_count":null},{"id":"2c71b85e77b4b181","cell_type":"markdown","source":"## Parte 4: Comparación visual entre TF-IDF y BM25\n\n### Actividad \n\n1. Utiliza un gráfico de barras para visualizar los scores obtenidos por cada documento según TF-IDF y BM25.\n2. Compara los rankings visualmente.\n3. Identifica: ¿Qué documentos obtienen scores más altos en un modelo que en otro?\n4. Sugiere: ¿A qué se podría deber esta diferencia?","metadata":{}},{"id":"16ad3d9d16c04d35","cell_type":"code","source":"# Pendiente de implementación (BM25)","metadata":{"trusted":true},"outputs":[],"execution_count":null},{"id":"b97d171655ecfb","cell_type":"markdown","source":"## Parte 5: Evaluación con consulta relevante\n\n### Actividad \n\n1. Elige una consulta y define qué documentos del corpus deberían considerarse relevantes.\n2. Evalúa Precision@3 o MAP para los rankings generados con TF-IDF y BM25.\n3. Responde: ¿Cuál modelo da mejores resultados respecto a tu criterio de relevancia?","metadata":{}},{"id":"6d5de59378900ca","cell_type":"code","source":"# Pendiente de implementación (BM25)","metadata":{"trusted":true},"outputs":[],"execution_count":null}]}